{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Ld1vn-7FEC",
        "outputId": "30f8307a-16e8-4bf0-b379-a9badfeb41a1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIoJAF0N4Reh"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Thesis/data/UPDATED_parisien_quotes_lemmatized_french.csv'\n",
        "standard_french_df = pd.read_csv(file_path)\n",
        "file_path = '/content/drive/MyDrive/Thesis/data/UPDATED_cameroun_quotes_lemmatized_french.csv'\n",
        "cameroonian_french_df = pd.read_csv(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "CpM8iR8QmF3n",
        "outputId": "fdd72cd6-be52-47ed-c7ac-3551cdc6558b"
      },
      "outputs": [],
      "source": [
        "standard_french_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y77sIpKBqzV6",
        "outputId": "b8ed68ca-a986-4465-eb9d-99e16b2e4b44"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "french_determiners = {\n",
        "    'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'au', 'aux',\n",
        "    'ce', 'cet', 'cette', 'ces', 'mon', 'ma', 'mes', 'se', 'on',\n",
        "    'ton', 'ta', 'tes', 'son', 'sa', 'ses', 'notre', 'nos',\n",
        "    'votre', 'vos', 'leur', 'leurs', 'l', 'n', 'c', '»', '«'\n",
        "}\n",
        "\n",
        "punctuation = set(string.punctuation + \"«»’[]…“”\")\n",
        "\n",
        "def clean_and_filter_tokens(df):\n",
        "    return [\n",
        "        word.lower().strip(string.punctuation + \"’\\\"“”\")  # Strip quotes/punct\n",
        "        for sentence in df['Quote'].dropna()\n",
        "        for word in sentence.split()\n",
        "        if word.lower().strip(string.punctuation + \"’\\\"“”\") not in french_determiners\n",
        "        and word.strip() not in punctuation\n",
        "        and len(word.strip()) > 1\n",
        "    ]\n",
        "\n",
        "standard_tokens = clean_and_filter_tokens(standard_french_df)\n",
        "cameroonian_tokens = clean_and_filter_tokens(cameroonian_french_df)\n",
        "\n",
        "standard_freq = Counter(standard_tokens).most_common(30)\n",
        "cameroonian_freq = Counter(cameroonian_tokens).most_common(30)\n",
        "\n",
        "standard_freq_df = pd.DataFrame(standard_freq, columns=['Word_Standard', 'Frequency_Standard'])\n",
        "cameroonian_freq_df = pd.DataFrame(cameroonian_freq, columns=['Word_Cameroon', 'Frequency_Cameroon'])\n",
        "freq_table = pd.concat([standard_freq_df, cameroonian_freq_df], axis=1)\n",
        "print(freq_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "ffjNhPIPsrz8",
        "outputId": "7939606c-0e2b-45d6-cb64-eea57b40f5d3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_frequency_chart(freq_df):\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 22,\n",
        "        'axes.titlesize': 22,\n",
        "        'axes.labelsize': 16,\n",
        "        'xtick.labelsize': 16,\n",
        "        'ytick.labelsize': 16,\n",
        "    })\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 12), sharey=True)\n",
        "\n",
        "    # Standard French\n",
        "    axes[0].barh(freq_df['Word_Standard'], freq_df['Frequency_Standard'], color='skyblue')\n",
        "    axes[0].set_title('Top 30 Words - Standard French')\n",
        "    axes[0].invert_yaxis()\n",
        "    axes[0].set_xlabel('Frequency')\n",
        "\n",
        "    # Cameroonian French\n",
        "    axes[1].barh(freq_df['Word_Cameroon'], freq_df['Frequency_Cameroon'], color='lightcoral')\n",
        "    axes[1].set_title('Top 30 Words - Cameroonian French')\n",
        "    axes[1].set_xlabel('Frequency')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_frequency_chart(freq_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWIFetG7ztAF"
      },
      "source": [
        "# Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjnLjc-C4pIi"
      },
      "outputs": [],
      "source": [
        "def parse_sentences(df):\n",
        "    parsed_data = []\n",
        "    for sentence in df['lemmatized_sentence']:\n",
        "        doc = nlp(sentence)\n",
        "        pos_tags = [token.pos_ for token in doc]\n",
        "        dependencies = [token.dep_ for token in doc]\n",
        "        parsed_data.append({\n",
        "            'sentence': sentence,\n",
        "            'pos_tags': pos_tags,\n",
        "            'dependencies': dependencies\n",
        "        })\n",
        "    return pd.DataFrame(parsed_data)\n",
        "\n",
        "standard_french_df['lemmatized_sentence'] = standard_french_df['lemmatized_quote'].apply(lambda tokens: ' '.join(eval(tokens)))\n",
        "cameroonian_french_df['lemmatized_sentence'] = cameroonian_french_df['lemmatized_quote'].apply(lambda tokens: ' '.join(eval(tokens)))\n",
        "\n",
        "standard_parsed = parse_sentences(standard_french_df)\n",
        "cameroonian_parsed = parse_sentences(cameroonian_french_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD70olvUYBS9",
        "outputId": "de45f33f-fe39-43a9-83b2-0e7788b5fe06"
      },
      "outputs": [],
      "source": [
        "standard_parsed.to_csv(\"standard_french_parsed.csv\", index=False, encoding=\"utf-8\")\n",
        "cameroonian_parsed.to_csv(\"cameroonian_french_parsed.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"CSV files saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4pgfMcNzreE",
        "outputId": "460ed632-984b-45a5-a127-a2317064b876"
      },
      "outputs": [],
      "source": [
        "df_check_std = pd.read_csv(\"standard_french_parsed.csv\")\n",
        "df_check_cmr = pd.read_csv(\"cameroonian_french_parsed.csv\")\n",
        "\n",
        "print(\"Standard French Data Sample:\")\n",
        "print(df_check_std.head())\n",
        "\n",
        "print(\"\\nCameroonian French Data Sample:\")\n",
        "print(df_check_cmr.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GKjPUCyz6lV",
        "outputId": "fbc1f55c-a73a-4d8e-8fbd-f43cd23d3760"
      },
      "outputs": [],
      "source": [
        "standard_parsed[\"Dialect\"] = \"Standard French\"\n",
        "cameroonian_parsed[\"Dialect\"] = \"Cameroonian French\"\n",
        "\n",
        "combined_df = pd.concat([standard_parsed, cameroonian_parsed])\n",
        "\n",
        "combined_df.to_csv(\"combined_french_parsed.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"Combined CSV file saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxDbTWDG7rsv"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from scipy.stats import chi2_contingency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cNdFIxV5g9C"
      },
      "outputs": [],
      "source": [
        "def get_pos_frequencies(parsed_df):\n",
        "    pos_counter = Counter()\n",
        "    for tags in parsed_df['pos_tags']:\n",
        "        pos_counter.update(tags)\n",
        "    return pos_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mmx9xoO5nzK",
        "outputId": "c9839624-43c9-4d06-bfda-78ed67cc141a"
      },
      "outputs": [],
      "source": [
        "standard_pos_freq = get_pos_frequencies(standard_parsed)\n",
        "print(\"Standard French POS Tag Frequencies:\", standard_pos_freq)\n",
        "cameroonian_pos_freq = get_pos_frequencies(cameroonian_parsed)\n",
        "print(\"Cameroon French POS Tag Frequencies:\", cameroonian_pos_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y-p1W8D5rFa"
      },
      "outputs": [],
      "source": [
        "def get_dependency_frequencies(parsed_df):\n",
        "    dep_counter = Counter()\n",
        "    for deps in parsed_df['dependencies']:\n",
        "        dep_counter.update(deps)\n",
        "    return dep_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqVjLXsN5tmI",
        "outputId": "b63749c4-acbb-4d80-fe22-e4f99209273c"
      },
      "outputs": [],
      "source": [
        "standard_dep_freq = get_dependency_frequencies(standard_parsed)\n",
        "print(\"Standard French Dependency Frequencies:\", standard_dep_freq)\n",
        "cameroonian_dep_freq = get_dependency_frequencies(cameroonian_parsed)\n",
        "print(\"Cameroon French Dependency Frequencies:\", cameroonian_dep_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y58lRu7NWrnn"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfoLqINQWjx6"
      },
      "outputs": [],
      "source": [
        "def extract_pos_sequences(parsed_data, sequence_length=2):\n",
        "    sequences = []\n",
        "    for pos_tags in parsed_data[\"pos_tags\"]:\n",
        "        if isinstance(pos_tags, list):\n",
        "            sequences.extend(zip(*[pos_tags[i:] for i in range(sequence_length)]))\n",
        "    return sequences\n",
        "\n",
        "standard_sequences = extract_pos_sequences(standard_parsed, sequence_length=2)\n",
        "cameroonian_sequences = extract_pos_sequences(cameroonian_parsed, sequence_length=2)\n",
        "\n",
        "standard_seq_freq = Counter(standard_sequences)\n",
        "cameroonian_seq_freq = Counter(cameroonian_sequences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdu6ixWfWmWh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_sequences = set(standard_seq_freq.keys()).union(set(cameroonian_seq_freq.keys()))\n",
        "data = {\n",
        "    \"Sequence\": [\" -> \".join(seq) for seq in all_sequences],\n",
        "    \"Standard French\": [standard_seq_freq[seq] for seq in all_sequences],\n",
        "    \"Cameroonian French\": [cameroonian_seq_freq[seq] for seq in all_sequences]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Normalize frequencies per 1,000 sequences\n",
        "df[\"Standard French (per 1k)\"] = df[\"Standard French\"] / sum(standard_seq_freq.values()) * 1000\n",
        "df[\"Cameroonian French (per 1k)\"] = df[\"Cameroonian French\"] / sum(cameroonian_seq_freq.values()) * 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENuD1CYkYfKi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "6VbS4oPHWpAa",
        "outputId": "af424b27-a179-42e0-b7aa-b973d491f723"
      },
      "outputs": [],
      "source": [
        "df[\"Difference\"] = abs(df[\"Standard French (per 1k)\"] - df[\"Cameroonian French (per 1k)\"])\n",
        "top_differences = df.nlargest(10, \"Difference\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(\n",
        "    x=\"Difference\",\n",
        "    y=\"Sequence\",\n",
        "    data=top_differences,\n",
        "    palette=\"coolwarm\"\n",
        ")\n",
        "plt.title(\"Top 10 POS Sequence Frequency Differences (Standard vs. Cameroonian French)\")\n",
        "plt.xlabel(\"Absolute Difference (per 1k sequences)\")\n",
        "plt.ylabel(\"POS Sequence\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbc5O4_2BisI",
        "outputId": "08bbf27a-50ce-4177-a975-d0f00a0b17a3"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "results = []\n",
        "\n",
        "total_standard = sum(standard_seq_freq.values())\n",
        "total_cameroonian = sum(cameroonian_seq_freq.values())\n",
        "\n",
        "for seq in all_sequences:\n",
        "    a = standard_seq_freq.get(seq, 0)\n",
        "    c = cameroonian_seq_freq.get(seq, 0)\n",
        "    b = total_standard - a\n",
        "    d = total_cameroonian - c\n",
        "\n",
        "    contingency = [[a, b], [c, d]]\n",
        "    chi2, p, dof, expected = chi2_contingency(contingency)\n",
        "\n",
        "    results.append({\n",
        "        \"Sequence\": \" -> \".join(seq),\n",
        "        \"Standard Count\": a,\n",
        "        \"Cameroonian Count\": c,\n",
        "        \"Chi2\": chi2,\n",
        "        \"p-value\": p\n",
        "    })\n",
        "\n",
        "chi2_df = pd.DataFrame(results)\n",
        "significant_df = chi2_df[chi2_df[\"p-value\"] < 0.05].sort_values(\"p-value\")\n",
        "\n",
        "print(significant_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY0XEaHOBu1q",
        "outputId": "89f97b1f-0096-4954-ab8b-2212121e6d76"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "pvals = chi2_df[\"p-value\"]\n",
        "_, corrected_pvals, _, _ = multipletests(pvals, method='fdr_bh')\n",
        "chi2_df[\"corrected p-value\"] = corrected_pvals\n",
        "significant_corrected = chi2_df[chi2_df[\"corrected p-value\"] < 0.05].sort_values(\"corrected p-value\")\n",
        "\n",
        "print(significant_corrected.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "uSNROGbfB30U",
        "outputId": "84d7344d-0019-4a91-e16f-f268dc409a66"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "top_n = 40\n",
        "\n",
        "plot_top = significant_corrected.head(top_n)\n",
        "\n",
        "# .sort_values(\"corrected p-value\", ascending=True)\n",
        "\n",
        "sns.barplot(\n",
        "    data=plot_top,\n",
        "    x=\"corrected p-value\",\n",
        "    y=\"Sequence\",\n",
        "    palette=\"viridis_r\"\n",
        ")\n",
        "\n",
        "\n",
        "plt.xlabel(\"p-value\")\n",
        "plt.ylabel(\"POS Sequence\")\n",
        "plt.xscale(\"log\")\n",
        "plt.xticks(fontsize=18)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yxvvAV0HWqdK",
        "outputId": "30870f3d-6eb5-451d-9df5-8e0007c9ee8c"
      },
      "outputs": [],
      "source": [
        "pivot_data = df.melt(\n",
        "    id_vars=\"Sequence\",\n",
        "    value_vars=[\"Standard French (per 1k)\", \"Cameroonian French (per 1k)\"],\n",
        "    var_name=\"Variety\",\n",
        "    value_name=\"Frequency\"\n",
        ")\n",
        "\n",
        "heatmap_data = pivot_data.pivot_table(\n",
        "    index=\"Sequence\",\n",
        "    columns=\"Variety\",\n",
        "    values=\"Frequency\",\n",
        "    aggfunc='first'\n",
        ")\n",
        "heatmap_data = heatmap_data.loc[heatmap_data.max(axis=1) > 10]\n",
        "plt.figure(figsize=(14, 16))\n",
        "sns.heatmap(\n",
        "    heatmap_data,\n",
        "    annot=True,\n",
        "    fmt=\".1f\",\n",
        "    cmap=\"viridis\",\n",
        "    cbar_kws={'label': 'Frequency per 1k Sequences'}\n",
        ")\n",
        "plt.title(\"POS Sequence Frequency Heatmap\")\n",
        "plt.ylabel(\"POS Sequence\")\n",
        "plt.xlabel(\"Variety\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_APgzXKbBCUk"
      },
      "outputs": [],
      "source": [
        "def get_dependency_vectors(df):\n",
        "    dependency_vectors = []\n",
        "    for sentence in df['lemmatized_sentence']:\n",
        "        doc = nlp(sentence)\n",
        "        dep_str = ' '.join([f\"{token.dep_}_{token.head.pos_}_{token.pos_}\" for token in doc])\n",
        "        dependency_vectors.append(dep_str)\n",
        "    return dependency_vectors\n",
        "\n",
        "standard_french_df['dependency_structure'] = get_dependency_vectors(standard_french_df)\n",
        "cameroonian_french_df['dependency_structure'] = get_dependency_vectors(cameroonian_french_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6CdOGW-Dnb0"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5Q3MuzhC-MH"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_standard = vectorizer.fit_transform(standard_french_df['dependency_structure'])\n",
        "X_cameroon = vectorizer.fit_transform(cameroonian_french_df['dependency_structure'])\n",
        "\n",
        "pca = PCA(n_components=50)\n",
        "X_pca_standard = pca.fit_transform(X_standard.toarray())\n",
        "X_pca_cameroon = pca.fit_transform(X_cameroon.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS9iVmi_DavO",
        "outputId": "cc487939-402d-408f-b6b0-92faa56d0b72"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "n_clusters = 20\n",
        "kmeans_standard = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "standard_french_df['cluster'] = kmeans_standard.fit_predict(X_pca_standard)\n",
        "\n",
        "kmeans_cameroon = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "cameroonian_french_df['cluster'] = kmeans_cameroon.fit_predict(X_pca_cameroon)\n",
        "\n",
        "print(standard_french_df[['lemmatized_sentence', 'cluster']].head())\n",
        "print(cameroonian_french_df[['lemmatized_sentence', 'cluster']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GlOCk-oF1LM"
      },
      "outputs": [],
      "source": [
        "pca_2d = PCA(n_components=2)\n",
        "X_pca_combined = np.vstack([X_pca_standard, X_pca_cameroon])\n",
        "X_2d_combined = pca_2d.fit_transform(X_pca_combined)\n",
        "\n",
        "X_2d_standard = X_2d_combined[:len(X_pca_standard)]\n",
        "X_2d_cameroon = X_2d_combined[len(X_pca_standard):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "-bMShu_DDcFC",
        "outputId": "77c79679-08b4-41d6-a30d-f0b2e77f7b7a"
      },
      "outputs": [],
      "source": [
        "pca_2d = PCA(n_components=2)\n",
        "X_2d_standard = pca_2d.fit_transform(X_pca_standard)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster in range(n_clusters):\n",
        "    plt.scatter(X_2d_standard[standard_french_df['cluster'] == cluster, 0], X_2d_standard[standard_french_df['cluster'] == cluster, 1], label=f'Cluster {cluster}')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.title('Sentence Clusters based on Dependency Structure for Standard French')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATUT5vvEJKF7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df_standard = pd.DataFrame(X_2d_standard, columns=['PCA1', 'PCA2'])\n",
        "\n",
        "Q1 = df_standard.quantile(0.25)\n",
        "Q3 = df_standard.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "filtered_df_standard = df_standard[~((df_standard < lower_bound) | (df_standard > upper_bound)).any(axis=1)]\n",
        "filtered_clusters = standard_french_df.loc[filtered_df_standard.index, 'cluster']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "_wng43WzJL6a",
        "outputId": "d14a4266-48c2-40ee-89f9-ee6b50feb10b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_points = filtered_df_standard[filtered_clusters == cluster]\n",
        "    plt.scatter(cluster_points['PCA1'], cluster_points['PCA2'], label=f'Cluster {cluster}', alpha=0.7)\n",
        "\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.title('Sentence Clusters (Without Outliers) for Standard French')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "RVsYwW_7HND9",
        "outputId": "79439403-0fe7-4522-ce0f-2d3e4af73e67"
      },
      "outputs": [],
      "source": [
        "pca_2d = PCA(n_components=2)\n",
        "X_2d_cameroon = pca_2d.fit_transform(X_pca_cameroon)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster in range(n_clusters):\n",
        "    plt.scatter(X_2d_cameroon[cameroonian_french_df['cluster'] == cluster, 0], X_2d_cameroon[cameroonian_french_df['cluster'] == cluster, 1], label=f'Cluster {cluster}')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.title('Sentence Clusters based on Dependency Structure for Cameroonian French')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwVGAhwh-11j",
        "outputId": "0e29929e-c264-4606-d6f0-396a77456a1e"
      },
      "outputs": [],
      "source": [
        "def prepare_chi_square_data(freq_dict1, freq_dict2):\n",
        "    all_keys = set(freq_dict1.keys()).union(set(freq_dict2.keys()))\n",
        "    data = [[freq_dict1.get(k, 0), freq_dict2.get(k, 0)] for k in all_keys]\n",
        "    return data\n",
        "\n",
        "pos_data = prepare_chi_square_data(standard_pos_freq, cameroonian_pos_freq)\n",
        "chi2, p, _, _ = chi2_contingency(pos_data)\n",
        "print(f\"POS Tag Chi-square test: chi2={chi2}, p-value={p}\")\n",
        "\n",
        "dep_data = prepare_chi_square_data(standard_dep_freq, cameroonian_dep_freq)\n",
        "chi2, p, _, _ = chi2_contingency(dep_data)\n",
        "print(f\"Dependency Chi-square test: chi2={chi2}, p-value={p}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHl_61E6DDtn",
        "outputId": "6195b05d-edba-4964-b2ab-1ed27b5218e2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "centroids_standard = kmeans_standard.cluster_centers_\n",
        "centroids_cameroon = kmeans_cameroon.cluster_centers_\n",
        "\n",
        "similarity_matrix = cosine_similarity(centroids_standard, centroids_cameroon)\n",
        "closest_clusters = np.argmax(similarity_matrix, axis=1)\n",
        "\n",
        "for i, match in enumerate(closest_clusters):\n",
        "    print(f\"Standard French Cluster {i} ↔ Cameroonian French Cluster {match} (Similarity: {similarity_matrix[i, match]:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cMPLCKSDukf",
        "outputId": "31b17c28-9c79-4761-b8b0-b9b165c925fc"
      },
      "outputs": [],
      "source": [
        "matched_cluster = 11\n",
        "\n",
        "# Get sentences from matched clusters\n",
        "standard_sentences = standard_french_df[standard_french_df['cluster'] == matched_cluster]['lemmatized_sentence']\n",
        "cameroonian_sentences = cameroonian_french_df[cameroonian_french_df['cluster'] == closest_clusters[matched_cluster]]['lemmatized_sentence']\n",
        "\n",
        "print(\"Standard French Sentences:\")\n",
        "print(standard_sentences.head())\n",
        "\n",
        "print(\"\\nCameroonian French Sentences:\")\n",
        "print(cameroonian_sentences.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "jcpt_YPuC_SG",
        "outputId": "7d88c7bc-b2c0-4567-c732-357c297f4bb1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(X_pca_standard[standard_french_df['cluster'] == matched_cluster, 0],\n",
        "            X_pca_standard[standard_french_df['cluster'] == matched_cluster, 1],\n",
        "            color='blue', label=f'Standard French Cluster {matched_cluster}')\n",
        "\n",
        "X_pca_cameroon_2d = PCA(n_components=2).fit_transform(X_pca_cameroon)  # Reduce to 2D\n",
        "plt.scatter(X_pca_cameroon_2d[cameroonian_french_df['cluster'] == closest_clusters[matched_cluster], 0],\n",
        "            X_pca_cameroon_2d[cameroonian_french_df['cluster'] == closest_clusters[matched_cluster], 1],\n",
        "            color='red', label=f'Cameroonian French Cluster {closest_clusters[matched_cluster]}')\n",
        "\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.legend()\n",
        "plt.title(f'Matching Clusters: Standard vs Cameroonian French')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MP6h0nKM0pjB"
      },
      "source": [
        "# Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpIC8fq-FtSU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_standard = pd.read_csv(\"standard_french_parsed.csv\")\n",
        "df_cameroonian = pd.read_csv(\"cameroonian_french_parsed.csv\")\n",
        "\n",
        "df_standard[\"sentence\"].to_csv(\"standard_french_sentences.txt\", index=False, header=False)\n",
        "df_cameroonian[\"sentence\"].to_csv(\"cameroonian_french_sentences.txt\", index=False, header=False)\n",
        "\n",
        "print(\"Text files created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHsqUZjfGOdu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fasttext\n",
        "\n",
        "print(\"Standard French Model Exists:\", os.path.exists(\"standard_french_fasttext.bin\"))\n",
        "print(\"Cameroonian French Model Exists:\", os.path.exists(\"cameroonian_french_fasttext.bin\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUdIE05GMrk"
      },
      "outputs": [],
      "source": [
        "model_std = fasttext.train_unsupervised(\"standard_french_sentences.txt\", model=\"skipgram\", dim=300, epoch=10)\n",
        "model_std.save_model(\"standard_french_fasttext.bin\")\n",
        "\n",
        "model_cmr = fasttext.train_unsupervised(\"cameroonian_french_sentences.txt\", model=\"skipgram\", dim=300, epoch=10)\n",
        "model_cmr.save_model(\"cameroonian_french_fasttext.bin\")\n",
        "\n",
        "print(\"FastText models trained and saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2HB0Dx-eE0N"
      },
      "outputs": [],
      "source": [
        "def get_fasttext_embedding(text):\n",
        "    words = text.split()\n",
        "    word_vectors = [ft.get_word_vector(word) for word in words if word in ft]\n",
        "    return np.mean(word_vectors, axis=0).tolist() if word_vectors else np.zeros(300).tolist()\n",
        "\n",
        "ft = fasttext.load_model('standard_french_fasttext.bin')\n",
        "standard_french_df[\"embedding\"] = standard_french_df[\"text\"].apply(get_fasttext_embedding)\n",
        "ft = fasttext.load_model('cameroonian_french_fasttext.bin')\n",
        "cameroonian_french_df[\"embedding\"] = cameroonian_french_df[\"text\"].apply(get_fasttext_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yTdvGOyFyYg"
      },
      "outputs": [],
      "source": [
        "ft_std = fasttext.load_model(\"standard_french_fasttext.bin\")\n",
        "ft_cmr = fasttext.load_model(\"cameroonian_french_fasttext.bin\")\n",
        "\n",
        "word = \"bonjour\"\n",
        "vec_std = ft_std.get_word_vector(word)\n",
        "vec_cmr = ft_cmr.get_word_vector(word)\n",
        "\n",
        "print(f\"Vector for '{word}' (Standard French):\", vec_std[:10])\n",
        "print(f\"Vector for '{word}' (Cameroonian French):\", vec_cmr[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaGJrp-VF0KV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_sentence_vector(model, sentence):\n",
        "    \"\"\"Generate a dense vector representation of a sentence.\"\"\"\n",
        "    words = sentence.split()\n",
        "    vectors = [model.get_word_vector(word) for word in words if word in model.words]\n",
        "\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(300)\n",
        "\n",
        "df_standard[\"embedding\"] = df_standard[\"sentence\"].apply(lambda x: get_sentence_vector(ft_std, str(x)))\n",
        "df_cameroonian[\"embedding\"] = df_cameroonian[\"sentence\"].apply(lambda x: get_sentence_vector(ft_cmr, str(x)))\n",
        "\n",
        "print(\"Sentence embeddings generated!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JVyPsGhF1q6"
      },
      "outputs": [],
      "source": [
        "df_standard.to_csv(\"UPDATED_standard_french_with_embeddings.csv\", index=False)\n",
        "df_cameroonian.to_csv(\"UPDATED_cameroonian_french_with_embeddings.csv\", index=False)\n",
        "\n",
        "print(\"Embeddings saved to CSV!\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
