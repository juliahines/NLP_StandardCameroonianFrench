{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsjefe1AEbh2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2hdL5V1Ld4k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "standard_french_df = pd.read_csv('/content/drive/MyDrive/Thesis/data/UPDATED_standard_french_with_embeddings.csv')\n",
        "cameroonian_french_df = pd.read_csv('/content/drive/MyDrive/Thesis/data/UPDATED_cameroonian_french_with_embeddings.csv')\n",
        "\n",
        "standard_french_df[\"label\"] = 0\n",
        "cameroonian_french_df[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([standard_french_df, cameroonian_french_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = df[['sentence', 'label']]\n",
        "df[\"sentence\"] = df[\"sentence\"].astype(str).fillna(\"\")\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"sentence\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "VOCAB_SIZE = 20000\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "EMBEDDING_DIM = 128\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, lower=True)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "X_train = tokenizer.texts_to_sequences(train_texts)\n",
        "X_test = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
        "    SpatialDropout1D(0.2),\n",
        "    LSTM(64, dropout=0.2, recurrent_dropout=0.2, return_sequences=True),\n",
        "    BatchNormalization(),\n",
        "    LSTM(32, dropout=0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test),\n",
        "                    verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"LSTM Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYmoRY6dVYyB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "report = classification_report(y_test, y_pred, digits=4)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQctsQdVEa7p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "standard_french_df = pd.read_csv('/content/drive/MyDrive/Thesis/data/UPDATED_standard_french_with_embeddings.csv')\n",
        "cameroonian_french_df = pd.read_csv('/content/drive/MyDrive/Thesis/data/UPDATED_cameroonian_french_with_embeddings.csv')\n",
        "\n",
        "standard_french_df[\"label\"] = 0\n",
        "cameroonian_french_df[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([standard_french_df, cameroonian_french_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = df[['sentence', 'label']]\n",
        "\n",
        "df[\"sentence\"] = df[\"sentence\"].astype(str).fillna(\"\")\n",
        "\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B3Fv9SrEreJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dataframe_to_tf_dataset(df, batch_size=32, shuffle=True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df[\"sentence\"].values, df[\"label\"].values))\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(df))\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "\n",
        "# Convert to Keras dataset\n",
        "train_dataset = dataframe_to_tf_dataset(train_df)\n",
        "test_dataset = dataframe_to_tf_dataset(test_df, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgbz8aXZExe2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "VOCAB_SIZE = 20000\n",
        "MAX_LEN = 200\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=VOCAB_SIZE, output_mode='int', output_sequence_length=MAX_LEN)\n",
        "\n",
        "text_ds = train_df[\"sentence\"].astype(str).values\n",
        "vectorizer.adapt(text_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmxy2ywmFEUD"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, mask_zero=True),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.build(input_shape=(None, MAX_LEN))\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Opo1I8egEv-M"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    vectorizer,\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, mask_zero=True),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.build(input_shape=(None, MAX_LEN))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfTqT4QFKnBw"
      },
      "outputs": [],
      "source": [
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, axis=-1)\n",
        "    return vectorizer(text), label\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.expand_dims(x, -1), y))\n",
        "test_dataset = test_dataset.map(lambda x, y: (tf.expand_dims(x, -1), y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZCTqxk_LZD5"
      },
      "outputs": [],
      "source": [
        "for text_batch, label_batch in train_dataset.take(1):\n",
        "    print(\"Text batch shape:\", text_batch.shape)\n",
        "    print(\"Label batch shape:\", label_batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV9y-mZ_FrCI"
      },
      "outputs": [],
      "source": [
        "text_samples = train_df[\"sentence\"].astype(str).values\n",
        "vectorizer.adapt(text_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8lggNpuFPqy"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, validation_data=test_dataset, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GC5dlCuFLtV"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMrwwbDs0dE0"
      },
      "source": [
        "# Logistic Regresion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQBTpSqpztas"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Thesis/data/UPDATED_standard_french_with_embeddings.csv'\n",
        "standard_french_df = pd.read_csv(file_path)\n",
        "file_path = '/content/drive/MyDrive/Thesis/data/UPDATED_cameroonian_french_with_embeddings.csv'\n",
        "cameroonian_french_df = pd.read_csv(file_path)\n",
        "\n",
        "standard_french_df[\"label\"] = 0\n",
        "cameroonian_french_df[\"label\"] = 1\n",
        "\n",
        "df = pd.concat([standard_french_df, cameroonian_french_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = df[['sentence', 'label']]\n",
        "df[\"sentence\"] = df[\"sentence\"].astype(str).fillna(\"\")\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"sentence\"], df[\"label\"], test_size=0.2, stratify=df[\"label\"], random_state=42\n",
        ")\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, train_labels)\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
